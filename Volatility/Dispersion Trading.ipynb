{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39cf292-1908-4e6f-b0c0-5d2349b186b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from scipy.optimize import minimize, Bounds, fmin_cg\n",
    "from skopt import gp_minimize\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas_datareader as pdr\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26fed8d0-67e4-4a27-b6cb-c254412ed58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  503 of 503 completed 503 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "['BF.B']: YFPricesMissingError('possibly delisted; no price data found  (1d 2018-12-19 -> 2025-03-05)')\n",
      "[*********************100%***********************]  503 of 503 completed['BRK.B']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#S&P 500 ticker\n",
    "SnP_componet_ticker = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0].Symbol\n",
    "Russell_1000_componet_ticker = pd.read_html('https://en.wikipedia.org/wiki/Russell_1000_Index')[3].Symbol\n",
    "SnP600_componet_ticker = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_600_companies')[0].Symbol\n",
    "\n",
    "def final_ticker(T_list):\n",
    "    return list(set(T_list))\n",
    "\n",
    "index_banch_mart = [\"SPY\"]\n",
    "\n",
    "tickers = final_ticker(SnP_componet_ticker)\n",
    "\n",
    "def get_stock_data(tickers_list, start_date, end_date):\n",
    "    \n",
    "    all_tickers = list(dict.fromkeys(tickers_list))\n",
    "    \n",
    "    data = yf.download(all_tickers, start=start_date, end=end_date)['Close']\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.dropna(axis=1)\n",
    "        available_tickers = list(data.columns)\n",
    "    else:\n",
    "        available_tickers = all_tickers\n",
    "    \n",
    "    return data, available_tickers\n",
    "\n",
    "end_date = datetime.date.today()\n",
    "start_date = end_date - datetime.timedelta(days=756*3) #3 years analysis\n",
    "\n",
    "\n",
    "df,tickers = get_stock_data(tickers,start_date,end_date)\n",
    "\n",
    "df_BM,_ = get_stock_data(index_banch_mart, start_date,end_date)\n",
    "number_of_stocks = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b329b0-74fe-414b-a4ae-fe4721187cd6",
   "metadata": {},
   "source": [
    "S&P 500 is weighted by free-float market capitalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fde9c3c-46f2-4c51-ab13-576013b14837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_caps(tickers):\n",
    "    market_caps = {}\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            market_cap = stock.info.get('marketCap', None)\n",
    "            if market_cap:\n",
    "                market_caps[ticker] = market_cap\n",
    "        except:\n",
    "            pass\n",
    "    return market_caps\n",
    "\n",
    "weights = {ticker: 1/len(tickers) for ticker in tickers}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61388082-911d-45ec-82bf-9dfc092e9c36",
   "metadata": {},
   "source": [
    "# Main idea:\n",
    "Take advantage of the mismatch between the volatility of index and it's constituent.\n",
    "$$\n",
    "\\sigma_\\mathrm{index}^2 = \\sum_{i} w_i^2\\sigma_i^2 + 2\\sum_{i \\neq j} \\rho_{ij}w_i w_j\\sigma_i\\sigma_j,\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_\\mathrm{weighted \\ stock} = \\sum_{i} w_i\\sigma_i.\n",
    "$$\n",
    "where $\\rho_{ij}$ is the correalation between stock $i$, $j$.\n",
    "\n",
    "Note \n",
    "$$\n",
    "\\sigma_\\mathrm{index} \\leq \\sigma_\\mathrm{weighted \\ stock}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8087e068-c67e-4f7d-983f-05a12df130ef",
   "metadata": {},
   "source": [
    "Trading logic:\n",
    "\n",
    "If $\\sigma_\\mathrm{index} \\leq \\sigma_\\mathrm{weighted \\ stock}$ and $\\rho_{ij}$ is low -> Short index volatility, long stock volatilities.\n",
    "\n",
    "If $\\sigma_\\mathrm{index} \\approx \\sigma_\\mathrm{weighted \\ stock}$ and $\\rho_{ij}$ is hight -> Long index volatility, short stock volatilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689acad-9a22-4381-9195-871a14da47ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_returns = df.pct_change().dropna()\n",
    "index_returns = df_BM.pct_change().dropna()\n",
    "\n",
    "stock_vols = stock_returns.rolling(window=20).std() * np.sqrt(252)  # Annualized\n",
    "index_vol = index_returns.rolling(window=20).std() * np.sqrt(252)  # Annualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3f4227e-b1fe-4eaa-a02b-3ea2501fed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_implied_correlation(index_vol_series, stock_vols_df, weights=None):\n",
    "    common_idx = index_vol_series.index.intersection(stock_vols_df.index)\n",
    "    index_vol_aligned = index_vol_series.loc[common_idx]\n",
    "    stock_vols_aligned = stock_vols_df.loc[common_idx]\n",
    "    \n",
    "    n = stock_vols_aligned.shape[1]\n",
    "    \n",
    "    if weights is None:\n",
    "        weights = {col: 1/n for col in stock_vols_aligned.columns}\n",
    "    \n",
    "    weight_array = np.array([weights.get(col, 1/n) for col in stock_vols_aligned.columns])\n",
    "    \n",
    "    weighted_vol_squared_sum = np.zeros(len(common_idx))\n",
    "    weighted_vol_sum_squared = np.zeros(len(common_idx))\n",
    "    \n",
    "    for i, date in enumerate(common_idx):\n",
    "        vols = stock_vols_aligned.loc[date].values\n",
    "        weighted_vol_squared_sum[i] = np.sum((weight_array**2) * (vols**2))\n",
    "        weighted_vol_sum = np.sum(weight_array * vols)\n",
    "        weighted_vol_sum_squared[i] = weighted_vol_sum**2\n",
    "    \n",
    "    index_vol_squared = index_vol_aligned.values**2\n",
    "    \n",
    "    numerator = index_vol_squared - weighted_vol_squared_sum\n",
    "    denominator = weighted_vol_sum_squared - weighted_vol_squared_sum\n",
    "    \n",
    "    implied_corr = pd.Series(numerator / denominator, index=common_idx)\n",
    "    return implied_corr.clip(-1, 1)\n",
    "\n",
    "\n",
    "def calculate_realized_correlation(returns, window=20):\n",
    "    avg_correlations = []\n",
    "    dates = []\n",
    "    \n",
    "    # Step through time, computing the average correlation at each point\n",
    "    for i in range(window, len(returns)):\n",
    "\n",
    "        window_returns = returns.iloc[i-window:i]\n",
    "        \n",
    "        # Calculate correlation matrix\n",
    "        corr_matrix = window_returns.corr().values\n",
    "        \n",
    "        # Get upper triangle (excluding diagonal)\n",
    "        mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "        upper_triangle = corr_matrix[mask]\n",
    "        \n",
    "        # Calculate average correlation\n",
    "        avg_corr = np.nanmean(upper_triangle)\n",
    "        avg_correlations.append(avg_corr)\n",
    "        dates.append(returns.index[i])\n",
    "    \n",
    "    return pd.Series(avg_correlations, index=dates)\n",
    "\n",
    "# Calculate correlations\n",
    "implied_corr = calculate_implied_correlation(index_vol.iloc[:, 0], stock_vols, weights)\n",
    "realized_corr = calculate_realized_correlation(stock_returns)\n",
    "\n",
    "# Make sure they're aligned\n",
    "common_idx = implied_corr.index.intersection(realized_corr.index)\n",
    "implied_corr = implied_corr.loc[common_idx]\n",
    "realized_corr = realized_corr.loc[common_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c3f0aee-c695-4df6-a9ab-208bda9d119c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-01-22    0.596614\n",
       "2019-01-23    0.595163\n",
       "2019-01-24    0.574804\n",
       "2019-01-25    0.503962\n",
       "2019-01-28    0.372128\n",
       "                ...   \n",
       "2025-02-26    0.116221\n",
       "2025-02-27    0.111575\n",
       "2025-02-28    0.111188\n",
       "2025-03-03    0.125135\n",
       "2025-03-04    0.124430\n",
       "Length: 1538, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realized_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e7ce5-9299-4dc2-a7f1-8ea6fcc23e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build trading strategy\n",
    "threshold = 0.1\n",
    "# Generate dispersion signal - 1 when implied > realized + threshold\n",
    "dispersion_signal = ((implied_corr - realized_corr) > threshold).astype(int)\n",
    "\n",
    "# Initialize P&L series\n",
    "dispersion_pnl = pd.Series(0.0, index=dispersion_signal.index[:-1])\n",
    "\n",
    "# Calculate P&L - fixing the error in your code\n",
    "for i in range(len(dispersion_signal) - 1):\n",
    "    current_date = dispersion_signal.index[i]\n",
    "    next_date = dispersion_signal.index[i+1]\n",
    "    \n",
    "    # Important fix: use .iloc[i] to get the scalar value, not a Series\n",
    "    signal_value = dispersion_signal.iloc[i]\n",
    "    \n",
    "    if signal_value == 1:\n",
    "        # We're in a dispersion trade\n",
    "        dispersion_pnl.loc[current_date] = implied_corr.loc[current_date] - realized_corr.loc[next_date]\n",
    "    else:\n",
    "        dispersion_pnl.loc[current_date] = 0\n",
    "\n",
    "# Calculate cumulative P&L\n",
    "cum_pnl = dispersion_pnl.cumsum()\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Implied vs Realized Correlation\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(implied_corr, label='Implied Correlation')\n",
    "plt.plot(realized_corr, label='Realized Correlation')\n",
    "plt.title('Implied vs Realized Correlation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 2: Dispersion Trading Signal\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(dispersion_signal)\n",
    "plt.title('Dispersion Trading Signal (1 = Trade)')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 3: Cumulative P&L\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(cum_pnl)\n",
    "plt.title('Cumulative P&L')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate performance metrics\n",
    "total_trades = dispersion_signal.sum()\n",
    "winning_trades = (dispersion_pnl > 0).sum()\n",
    "win_rate = winning_trades / total_trades if total_trades > 0 else 0\n",
    "avg_win = dispersion_pnl[dispersion_pnl > 0].mean() if winning_trades > 0 else 0\n",
    "avg_loss = dispersion_pnl[dispersion_pnl < 0].mean() if (dispersion_pnl < 0).sum() > 0 else 0\n",
    "profit_factor = abs(dispersion_pnl[dispersion_pnl > 0].sum() / dispersion_pnl[dispersion_pnl < 0].sum()) if dispersion_pnl[dispersion_pnl < 0].sum() != 0 else float('inf')\n",
    "\n",
    "print(f\"Dispersion Trading Backtest Results:\")\n",
    "print(f\"Total Trades: {total_trades}\")\n",
    "print(f\"Win Rate: {win_rate:.2%}\")\n",
    "print(f\"Average Win: {avg_win:.4f}\")\n",
    "print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "print(f\"Profit Factor: {profit_factor:.2f}\")\n",
    "print(f\"Total P&L: {cum_pnl.iloc[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed507980-65a8-4877-a2ae-5dd466121764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
